{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f8cb96b",
   "metadata": {},
   "source": [
    "### Load  JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070cc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read the JSON data\n",
    "with open('../data/data.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Process each item with a progress bar\n",
    "for item in tqdm(data, desc=\"Processing items\"):\n",
    "    print(f\"Processing item: {item['name']}\")\n",
    "\n",
    "# The total number of items\n",
    "print(f\"Total items: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c968720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init env variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c08e8",
   "metadata": {},
   "source": [
    "### Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43476ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
    "from langchain_core.documents import Document\n",
    "from app_utils import generate_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ff666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[5]['metadata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08949413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each items load the documents from the 'path' key depending on the file type text or pdf\n",
    "def load_documents(item) -> list[Document]:\n",
    "    type = item.get(\"type\")\n",
    "    path = f'../{item.get(\"path\")}'\n",
    "    if type == \"text\":\n",
    "        loader = TextLoader(path)\n",
    "    elif type == \"pdf\":\n",
    "        loader = PyPDFLoader(path)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {path}\")\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Add metadata to each document (create a copy to avoid modifying original data)\n",
    "    metadata = item.get(\"metadata\", {}).copy()\n",
    "\n",
    "    # The metadata technologies is a list, convert it to a comma-separated string\n",
    "    if \"technologies\" in metadata and isinstance(metadata[\"technologies\"], list):\n",
    "        technologies = metadata[\"technologies\"]\n",
    "        metadata[\"technologies\"] = \", \".join(technologies)\n",
    "\n",
    "        # add each technology as a separate metadata key with value True\n",
    "        for tech in technologies:\n",
    "            metadata[generate_key(tech)] = True\n",
    "\n",
    "    for doc in documents:\n",
    "        doc.metadata.update(metadata)\n",
    "\n",
    "    return documents\n",
    "\n",
    "print(data[5]['metadata'])\n",
    "load_documents(data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183bf369",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for item in tqdm(data, desc=\"Loading documents\", unit=\"item\"):\n",
    "    path = f'../{item.get(\"path\")}'\n",
    "    type = item.get(\"type\")\n",
    "    if path and type:\n",
    "        try:\n",
    "            documents.extend(load_documents(item))\n",
    "            #print(f\"Loaded {len(documents)} documents from {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading documents from {path}: {e}\")\n",
    "    else:\n",
    "        print(f\"No valid path or type for item: {item['name']}\")\n",
    "\n",
    "print(f\"Total documents loaded: {len(documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76f10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[5].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d75b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text spliting\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    add_start_index=True\n",
    ")\n",
    "all_chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Number of text chunks created: {len(all_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f0171",
   "metadata": {},
   "source": [
    "### Embedding and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8238891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "db_name = \"../chroma_db\"\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Delete existing ChromaDB database folder if it exists\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "    print(f\"Deleted existing database folder: {db_name}\")\n",
    "\n",
    "# Create and persist the ChromaDB database\n",
    "vectordb = Chroma(\n",
    "    collection_name=\"freelance_data\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=db_name,\n",
    ")\n",
    "\n",
    "# index the documents\n",
    "ids = vectordb.add_documents(all_chunks)\n",
    "print(f\"Number of documents indexed: {len(ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736ead89",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a09075",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vectordb.similarity_search(\"Example of one AI project\", k=2)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34056052",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(\n",
    "    search_kwargs={\"k\": 2},\n",
    "    search_type=\"similarity\"\n",
    ")\n",
    "\n",
    "retriever.batch(\n",
    "    [\n",
    "        \"Who is he?\",\n",
    "        \"What is Lo√Øc's current position?\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152aae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter metadata example\n",
    "filtered_results = vectordb.similarity_search(\n",
    "    \"AI project\",\n",
    "    k=2,\n",
    "    filter={\"category\": \"About Me\"}\n",
    ")\n",
    "filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4eb54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = generate_key(\"AI\")\n",
    "key2 = generate_key(\"Flutter\")\n",
    "\n",
    "filtered_results = vectordb.similarity_search(\n",
    "    \"Flutter\",\n",
    "    k=2,\n",
    "    filter={'$and': [{key1: True}, {key2: True}]}\n",
    ")\n",
    "filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35161e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the LangChain Chroma API to query with filters\n",
    "results = vectordb.similarity_search(\n",
    "    \"Exemple de projet d'IA\",\n",
    "    k=10,\n",
    "    filter={'$or': [{'ai': True}, {'dart': True}]}\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab8f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proposal_generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
